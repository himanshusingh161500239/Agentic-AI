{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed9d65ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.tools.langchain import LangChainToolAdapter\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# ALL_IN_ONE_WORKER = True\n",
    "ALL_IN_ONE_WORKER = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f966c9be",
   "metadata": {},
   "source": [
    "<h3>Define a Message Class</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2020a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    content:str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa75443",
   "metadata": {},
   "source": [
    "<h3> Define a host for distributed runtime</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52f8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntimeHost\n",
    "host = GrpcWorkerAgentRuntimeHost(address=\"localhost:50051\")\n",
    "host.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84b379",
   "metadata": {},
   "source": [
    "<h3>Create a Tool</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f99b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "serper = GoogleSerperAPIWrapper()\n",
    "langchain_serper = Tool(name=\"internet_search\",func=serper.run, description=\"Useful for when you need to search the internet\")\n",
    "autogen_serper = LangChainToolAdapter(langchain_serper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7a79555",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction1 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons in favor of choosing AutoGen; the pros of AutoGen.\"\n",
    "\n",
    "instruction2 = \"To help with a decision on whether to use AutoGen in a new AI Agent project, \\\n",
    "please research and briefly respond with reasons against choosing AutoGen; the cons of Autogen.\"\n",
    "\n",
    "judge = \"You must make a decision on whether to use AutoGen for a project. \\\n",
    "Your research team has come up with the following reasons for and against. \\\n",
    "Based purely on the research from your team, please respond with your decision and brief rationale.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5423bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            api_key=os.getenv('GEMINI_ACCESS_KEY'),\n",
    "            model_info={\n",
    "                \"vision\": False,\n",
    "                \"function_calling\": True,\n",
    "                \"json_output\": False,  # or True if you expect structured responses\n",
    "                \"family\": \"gemini-2.5-flash\"\n",
    "            },\n",
    "        )\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            api_key=os.getenv('GEMINI_ACCESS_KEY'),\n",
    "            model_info={\n",
    "                \"vision\": False,\n",
    "                \"function_calling\": True,\n",
    "                \"json_output\": False,  # or True if you expect structured responses\n",
    "                \"family\": \"gemini-2.5-flash\"\n",
    "            },\n",
    "        )\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client, tools=[autogen_serper], reflect_on_tool_use=True)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "    \n",
    "class Judge(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            api_key=os.getenv('GEMINI_ACCESS_KEY'),\n",
    "            model_info={\n",
    "                \"vision\": False,\n",
    "                \"function_calling\": True,\n",
    "                \"json_output\": False,  # or True if you expect structured responses\n",
    "                \"family\": \"gemini-2.5-flash\"\n",
    "            },\n",
    "        )\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "        \n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        message1 = Message(content=instruction1)\n",
    "        message2 = Message(content=instruction2)\n",
    "        inner_1 = AgentId(\"player1\", \"default\")\n",
    "        inner_2 = AgentId(\"player2\", \"default\")\n",
    "        response1 = await self.send_message(message1, inner_1)\n",
    "        response2 = await self.send_message(message2, inner_2)\n",
    "        result = f\"## Pros of AutoGen:\\n{response1.content}\\n\\n## Cons of AutoGen:\\n{response2.content}\\n\\n\"\n",
    "        judgement = f\"{judge}\\n{result}Respond with your decision and brief explanation\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + \"\\n\\n## Decision:\\n\\n\" + response.chat_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f866524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/himanshu.r.singh/Desktop/AgenticAI/agenticAI/lib/python3.13/site-packages/autogen_ext/models/openai/_openai_client.py:439: UserWarning: Missing required field 'structured_output' in ModelInfo. This field will be required in a future version of AutoGen.\n",
      "  validate_model_info(self._model_info)\n"
     ]
    }
   ],
   "source": [
    "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntime\n",
    "\n",
    "if ALL_IN_ONE_WORKER:\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "\n",
    "    await Player1Agent.register(worker, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "    await Player2Agent.register(worker, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "\n",
    "    agent_id = AgentId(\"judge\", \"default\")\n",
    "\n",
    "else:\n",
    "\n",
    "    worker1 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker1.start()\n",
    "    await Player1Agent.register(worker1, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "\n",
    "    worker2 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker2.start()\n",
    "    await Player2Agent.register(worker2, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "\n",
    "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
    "    await worker.start()\n",
    "    await Judge.register(worker, \"judge\", lambda: Judge(\"judge\"))\n",
    "    agent_id = AgentId(\"judge\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca40b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await worker.send_message(Message(content=\"Go!\"), agent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da190676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Pros of AutoGen:\n",
       "AutoGen offers several compelling advantages for new AI Agent projects, including:\n",
       "\n",
       "*   **Multi-Agent Collaboration:** It excels at orchestrating dynamic conversations and collaborations between multiple AI agents, allowing them to work together like a team to solve complex tasks.\n",
       "*   **Scalability and Modularity:** The framework is designed for scalability and modularity, making it suitable for both simple and complex multi-agent scenarios and facilitating the creation of customizable systems.\n",
       "*   **Ease of Use & Development Acceleration:** AutoGen provides an easy-to-use and flexible framework that accelerates the development and research of agentic AI. It simplifies the creation of collaborative, task-oriented agents.\n",
       "*   **Customization:** It offers high customization, allowing users to define specific roles, capabilities, and communication protocols for each agent.\n",
       "*   **Integrated Observability & Debugging:** AutoGen includes integrated tools for observing and debugging agent workflows, simplifying monitoring and control.\n",
       "*   **Human-in-the-Loop Capabilities:** It supports human-in-the-loop workflows, ensuring that human oversight and intervention can be integrated into AI-powered processes.\n",
       "*   **LLM Optimization:** AutoGen is also noted for its capabilities in LLM optimization within multi-agent setups.\n",
       "\n",
       "These features make AutoGen a strong candidate for projects requiring sophisticated, collaborative, and scalable AI agent solutions.\n",
       "\n",
       "TERMINATE\n",
       "\n",
       "## Cons of AutoGen:\n",
       "Here are some reasons against choosing AutoGen for a new AI Agent project:\n",
       "\n",
       "*   **Still Under Development:** AutoGen is relatively new and actively being developed. This can mean less stability, fewer mature features, and potential breaking changes in future updates.\n",
       "*   **Steep Learning Curve/Complexity:** While powerful, AutoGen can be complex to set up and configure, especially for advanced multi-agent workflows. There's a trade-off between customization and ease of use, and achieving fine-grained control often requires significant effort.\n",
       "*   **Limitations in Creativity (for some tasks):** While good at structured content generation and task execution, AutoGen might lack the \"creativity\" or nuanced understanding required for highly open-ended or subjective tasks where human-like improvisation is needed. It operates based on defined agents and their roles.\n",
       "*   **Suitability for Customer-Facing Applications:** There are concerns about its direct suitability for highly sensitive or critical customer-facing applications without significant additional layers of validation and control, due to the nature of autonomous agent interactions.\n",
       "*   **Resource Intensiveness:** Running multiple agents, especially for complex tasks, can be resource-intensive in terms of computational power and API calls.\n",
       "\n",
       "\n",
       "\n",
       "## Decision:\n",
       "\n",
       "Based purely on the research provided, I recommend **using AutoGen** for a new AI Agent project.\n",
       "\n",
       "**Rationale:**\n",
       "AutoGen's strengths, particularly its multi-agent collaboration, scalability, modularity, and development acceleration features, are highly compelling for a *new* AI agent project. It offers a robust framework for building complex, collaborative systems with good customization and integrated debugging. While the \"still under development\" and \"steep learning curve\" cons are valid concerns, the benefits of accelerating development and enabling sophisticated multi-agent interactions appear to outweigh these risks for a new project, especially one that can tolerate potential changes or invest in the initial learning. Concerns about creativity limitations or direct suitability for highly sensitive customer-facing applications are important but can be managed or considered in later project phases, rather than being immediate blockers for *starting* a new agent project.\n",
       "\n",
       "TERMINATE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461e456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await worker.stop()\n",
    "if not ALL_IN_ONE_WORKER:\n",
    "    await worker1.stop()\n",
    "    await worker2.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ec1baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "await host.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
